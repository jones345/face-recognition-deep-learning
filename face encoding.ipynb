{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2b04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6f184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg files into numpy arrays\n",
    "image = face_recognition.load_image_file(\"person.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the face encodings\n",
    "face_encodings = face_recognition.face_encodings(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2afb907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20855837  0.01845226  0.05200073 -0.01912922 -0.02748854 -0.01855117\n",
      " -0.027255   -0.01845023  0.19835591 -0.01124563  0.19645655  0.01600665\n",
      " -0.15621799 -0.08862405 -0.00915151  0.11604425 -0.12597199 -0.14229293\n",
      " -0.03572801 -0.03505832  0.03726116  0.03980891 -0.07782653  0.07926028\n",
      " -0.14744216 -0.34706149 -0.10856137 -0.12216783  0.01723715 -0.11650674\n",
      "  0.06511289 -0.03900207 -0.18297048 -0.10930699  0.06847547  0.12637658\n",
      " -0.05037975 -0.09572256  0.13429828 -0.00703454 -0.16005868 -0.0557308\n",
      "  0.08435319  0.27441856  0.13435347  0.08523711  0.00496125 -0.11246422\n",
      "  0.16313241 -0.27373853  0.08402456  0.10128957  0.15344822  0.108321\n",
      "  0.11609212 -0.09201837  0.07474779  0.254884   -0.30816704  0.10207555\n",
      "  0.00198605 -0.01495524  0.03411678 -0.02620059  0.21705669  0.14441353\n",
      " -0.11093335 -0.12751675  0.17208098 -0.16183105 -0.04968167  0.12839431\n",
      " -0.03207513 -0.26411179 -0.31615093  0.07128873  0.36264002  0.18028145\n",
      " -0.13117109 -0.01013268 -0.05811105 -0.00737815  0.03560945  0.03457598\n",
      " -0.09948459 -0.06623539 -0.05779984 -0.01711861  0.24389154  0.12510221\n",
      "  0.003106    0.16942374 -0.01417198 -0.02782673  0.001431    0.06574464\n",
      " -0.10071306  0.00664665 -0.07640257 -0.06614345  0.03114731  0.03002048\n",
      "  0.07674068  0.13323891 -0.21063036  0.15302028 -0.0154896  -0.04833602\n",
      "  0.00523049 -0.02149037 -0.06463669  0.01915049  0.14195821 -0.29341784\n",
      "  0.22209316  0.12297856  0.04837456  0.15621082  0.00215635  0.00968098\n",
      " -0.03717988 -0.1172902  -0.17494754 -0.01424954  0.05999131 -0.07590403\n",
      "  0.0759552  -0.00694486]\n"
     ]
    }
   ],
   "source": [
    "if len(face_encodings) == 0:\n",
    "    # No faces found in the image.\n",
    "    print(\"No faces were found.\")\n",
    "\n",
    "else:\n",
    "    # Grab the first face encoding\n",
    "    first_face_encoding = face_encodings[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(first_face_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b704ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python394jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
